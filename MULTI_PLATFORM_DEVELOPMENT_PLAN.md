# å¤šå¹³å°é›†æˆå¼€å‘è®¡åˆ’æ–‡æ¡£
# Multi-Platform Integration Development Plan

**é¡¹ç›®**: Web3 TGE Monitor  
**ç‰ˆæœ¬**: v1.0  
**æ—¥æœŸ**: 2025-07-13  
**çŠ¶æ€**: å¼€å‘è®¡åˆ’  

---

## ç›®å½•

1. [é¡¹ç›®æ¦‚è¿°](#1-é¡¹ç›®æ¦‚è¿°)
2. [æŠ€æœ¯æ¶æ„è®¾è®¡](#2-æŠ€æœ¯æ¶æ„è®¾è®¡)
3. [å››é˜¶æ®µå®æ–½è®¡åˆ’](#3-å››é˜¶æ®µå®æ–½è®¡åˆ’)
4. [æŠ€æœ¯å®ç°è§„èŒƒ](#4-æŠ€æœ¯å®ç°è§„èŒƒ)
5. [é£é™©ç®¡ç†](#5-é£é™©ç®¡ç†)
6. [æµ‹è¯•ç­–ç•¥](#6-æµ‹è¯•ç­–ç•¥)
7. [é¡¹ç›®ç®¡ç†](#7-é¡¹ç›®ç®¡ç†)
8. [é™„å½•](#8-é™„å½•)

---

## 1. é¡¹ç›®æ¦‚è¿°

### 1.1 å½“å‰çŠ¶æ€åˆ†æ

**ç°æœ‰æ¶æ„ä¼˜åŠ¿:**
- âœ… å®Œå–„çš„æŠ½è±¡å±‚è®¾è®¡ (`AbstractPlatform` åŸºç±»)
- âœ… å·¥å‚æ¨¡å¼ç®¡ç† (`PlatformFactory` æ”¯æŒåŠ¨æ€æ³¨å†Œ)
- âœ… MediaCrawlerå¤šå¹³å°åº•å±‚æ”¯æŒ (6ä¸ªä¸»æµå¹³å°)
- âœ… ç»Ÿä¸€æ•°æ®æ¨¡å‹ (`RawContent` æ ‡å‡†åŒ–)
- âœ… APIé›†æˆå®Œæ•´ (æ”¯æŒå¤šå¹³å°å‚æ•°)
- âœ… æ¨¡æ¿ä»£ç å®Œå¤‡ (`template_platform.py`)

**å½“å‰é™åˆ¶:**
- ä»…æ”¯æŒå°çº¢ä¹¦(XHS)å•ä¸€å¹³å°
- æ•°æ®æ¥æºå•ä¸€ï¼Œè¦†ç›–é¢æœ‰é™
- ä¾èµ–å•ä¸€å¹³å°å­˜åœ¨é£é™©

### 1.2 é›†æˆç›®æ ‡

**ä¸»è¦ç›®æ ‡:**
- æ‰©å±•æ”¯æŒ6ä¸ªä¸»æµç¤¾äº¤åª’ä½“å¹³å°
- æå‡Web3/TGEå†…å®¹è¦†ç›–ç‡500%+
- å¢å¼ºå®æ—¶ç›‘æ§èƒ½åŠ›
- é™ä½å•ä¸€å¹³å°ä¾èµ–é£é™©

**æ”¯æŒå¹³å°åˆ—è¡¨:**
1. ğŸ”´ **å¾®åš** (weibo) - ä¿¡æ¯æµå¹³å°ï¼ŒåŠ å¯†è´§å¸è®¨è®ºæ´»è·ƒ
2. ğŸŸ¡ **çŸ¥ä¹** (zhihu) - é—®ç­”å¹³å°ï¼Œæ·±åº¦Web3åˆ†æå†…å®¹
3. ğŸ”µ **Bç«™** (bilibili) - è§†é¢‘å¹³å°ï¼ŒæŠ€æœ¯ç±»Web3å†…å®¹ä¸°å¯Œ
4. ğŸŸ£ **æŠ–éŸ³** (douyin) - çŸ­è§†é¢‘å¹³å°ï¼Œè§¦è¾¾å¹´è½»ç”¨æˆ·ç¾¤ä½“
5. ğŸŸ  **å¿«æ‰‹** (kuaishou) - çŸ­è§†é¢‘å¹³å°ï¼Œä¸‹æ²‰å¸‚åœºè¦†ç›–
6. ğŸŸ¢ **è´´å§** (tieba) - è®ºå›å¹³å°ï¼Œç‰¹å®šé¡¹ç›®è®¨è®ºç¤¾åŒº

### 1.3 æŠ€æœ¯å¯è¡Œæ€§

**æ¶æ„å…¼å®¹æ€§**: â­â­â­â­â­
- ç°æœ‰æ¶æ„å®Œå…¨æ”¯æŒå¤šå¹³å°æ‰©å±•
- æ— éœ€é‡æ„ï¼Œä»…éœ€å¢é‡å¼€å‘

**MediaCrawleræ”¯æŒ**: â­â­â­â­â­
- åº•å±‚å·²æ”¯æŒæ‰€æœ‰ç›®æ ‡å¹³å°
- ç™»å½•æœºåˆ¶å’Œæ•°æ®æŠ“å–å®Œå¤‡

**å¼€å‘å¤æ‚åº¦**: â­â­â­
- æ¯ä¸ªå¹³å°çº¦2-3å°æ—¶å¼€å‘é‡
- æ ‡å‡†åŒ–æ¨¡æ¿é™ä½å®ç°éš¾åº¦

---

## 2. æŠ€æœ¯æ¶æ„è®¾è®¡

### 2.1 å¤šå¹³å°æŠ½è±¡æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    API Layer (FastAPI)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 Platform Factory                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚     XHS     â”‚    Weibo    â”‚    Zhihu    â”‚   Bilibili  â”‚  â”‚
â”‚  â”‚  Platform   â”‚  Platform   â”‚  Platform   â”‚  Platform   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                AbstractPlatform Interface                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   MediaCrawler Engine                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                Unified Data Model (RawContent)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    Database Layer                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 æ ¸å¿ƒç»„ä»¶è®¾è®¡

#### 2.2.1 å¹³å°é€‚é…å™¨æ¥å£

```python
# src/crawler/platforms/base.py
class AbstractPlatform(ABC):
    """å¤šå¹³å°ç»Ÿä¸€æŠ½è±¡æ¥å£"""
    
    @abstractmethod
    async def search(self, keywords: List[str], max_pages: int = 10) -> List[RawContent]:
        """æœç´¢å†…å®¹æ¥å£"""
        pass
    
    @abstractmethod
    async def login(self) -> bool:
        """ç™»å½•éªŒè¯æ¥å£"""
        pass
    
    @abstractmethod
    def get_platform_name(self) -> str:
        """è·å–å¹³å°åç§°"""
        pass
```

#### 2.2.2 å·¥å‚æ¨¡å¼ç®¡ç†

```python
# src/crawler/platform_factory.py
class PlatformFactory:
    """å¹³å°å·¥å‚ç±» - ç»Ÿä¸€ç®¡ç†æ‰€æœ‰å¹³å°"""
    
    _platforms = {
        Platform.XHS: XHSPlatform,
        Platform.WEIBO: WeiboPlatform,      # æ–°å¢
        Platform.ZHIHU: ZhihuPlatform,      # æ–°å¢
        Platform.BILIBILI: BilibiliPlatform, # æ–°å¢
        Platform.DOUYIN: DouyinPlatform,    # æ–°å¢
        Platform.KUAISHOU: KuaishouPlatform, # æ–°å¢
        Platform.TIEBA: TiebaPlatform,      # æ–°å¢
    }
```

#### 2.2.3 ç»Ÿä¸€æ•°æ®æ¨¡å‹

```python
# src/crawler/models.py
@dataclass
class RawContent:
    """ç»Ÿä¸€æ•°æ®æ¨¡å‹ - é€‚é…æ‰€æœ‰å¹³å°"""
    
    content_id: str
    platform: str          # å¹³å°æ ‡è¯†
    title: str
    content: str
    author: str
    publish_time: Optional[datetime]
    url: Optional[str]
    images: List[str] = field(default_factory=list)
    videos: List[str] = field(default_factory=list)  # æ”¯æŒè§†é¢‘å†…å®¹
    tags: List[str] = field(default_factory=list)
    engagement: Dict[str, int] = field(default_factory=dict)  # äº’åŠ¨æ•°æ®
    platform_specific: Dict[str, Any] = field(default_factory=dict)  # å¹³å°ç‰¹æœ‰æ•°æ®
```

### 2.3 é…ç½®ç®¡ç†ç­–ç•¥

#### 2.3.1 ç¯å¢ƒå˜é‡æ‰©å±•

```bash
# .env æ–°å¢é…ç½®é¡¹
# å¾®åšå¹³å°é…ç½®
WEIBO_COOKIE=""
WEIBO_SEARCH_TYPE="ç»¼åˆ"  # ç»¼åˆ/å®æ—¶/çƒ­é—¨
WEIBO_MAX_PAGES=10
WEIBO_RATE_LIMIT=60

# çŸ¥ä¹å¹³å°é…ç½®
ZHIHU_COOKIE=""
ZHIHU_SEARCH_TYPE="ç»¼åˆ"
ZHIHU_MAX_PAGES=10
ZHIHU_RATE_LIMIT=60

# Bç«™å¹³å°é…ç½®
BILIBILI_COOKIE=""
BILIBILI_SEARCH_TYPE="è§†é¢‘"  # è§†é¢‘/ä¸“æ /ç”¨æˆ·
BILIBILI_MAX_PAGES=10
BILIBILI_RATE_LIMIT=60

# æŠ–éŸ³å¹³å°é…ç½®
DOUYIN_COOKIE=""
DOUYIN_MAX_PAGES=10
DOUYIN_RATE_LIMIT=60

# å¿«æ‰‹å¹³å°é…ç½®
KUAISHOU_COOKIE=""
KUAISHOU_MAX_PAGES=10
KUAISHOU_RATE_LIMIT=60

# è´´å§å¹³å°é…ç½®
TIEBA_COOKIE=""
TIEBA_MAX_PAGES=10
TIEBA_RATE_LIMIT=60
```

#### 2.3.2 å¹³å°ç‰¹å®šé…ç½®

```python
# src/config/platform_configs.py
PLATFORM_CONFIGS = {
    Platform.WEIBO: {
        'search_types': ['ç»¼åˆ', 'å®æ—¶', 'çƒ­é—¨'],
        'content_types': ['å¾®åš', 'æ–‡ç« '],
        'rate_limit': 60,
        'max_pages_default': 10
    },
    Platform.ZHIHU: {
        'search_types': ['ç»¼åˆ', 'é—®é¢˜', 'å›ç­”', 'æ–‡ç« '],
        'content_types': ['é—®é¢˜', 'å›ç­”', 'æ–‡ç« ', 'æƒ³æ³•'],
        'rate_limit': 60,
        'max_pages_default': 10
    },
    Platform.BILIBILI: {
        'search_types': ['è§†é¢‘', 'ç•ªå‰§', 'å½±è§†', 'ä¸“æ '],
        'categories': ['ç§‘æŠ€', 'è´¢ç»', 'çŸ¥è¯†'],
        'rate_limit': 60,
        'max_pages_default': 10
    }
}
```

---

## 3. å››é˜¶æ®µå®æ–½è®¡åˆ’

### Phase 1: å¾®åšå¹³å°é›†æˆ (ä¼˜å…ˆçº§: é«˜)

**æ—¶é—´ä¼°ç®—**: 2-3å°æ—¶  
**æŠ€æœ¯å¤æ‚åº¦**: â­â­â­  
**ä¸šåŠ¡ä»·å€¼**: â­â­â­â­â­  

#### 3.1.1 å¼€å‘ä»»åŠ¡

1. **åˆ›å»ºå¾®åšå¹³å°é€‚é…å™¨**
   - æ–‡ä»¶: `src/crawler/platforms/weibo_platform.py`
   - åŸºäº: `template_platform.py`
   - å®ç°: WeiboPlatformç±»

2. **æ•°æ®æ ¼å¼è½¬æ¢**
   - å¾®åšå†…å®¹ç»“æ„è§£æ
   - è½¬å‘/è¯„è®ºæ•°æ®å¤„ç†
   - å›¾ç‰‡/è§†é¢‘URLæå–

3. **é…ç½®é›†æˆ**
   - Platformæšä¸¾æ·»åŠ WEIBO
   - PlatformFactoryæ³¨å†Œ
   - ç¯å¢ƒå˜é‡é…ç½®

4. **æµ‹è¯•éªŒè¯**
   - å•å…ƒæµ‹è¯•ç¼–å†™
   - ç™»å½•æœºåˆ¶éªŒè¯
   - APIé›†æˆæµ‹è¯•

#### 3.1.2 å®ç°ç»†èŠ‚

```python
# src/crawler/platforms/weibo_platform.py
class WeiboPlatform(AbstractPlatform):
    """å¾®åšå¹³å°é€‚é…å™¨"""
    
    def __init__(self):
        self.platform_name = "weibo"
        self.crawler = WeiboClient()  # MediaCrawlerå®¢æˆ·ç«¯
        
    async def search(self, keywords: List[str], max_pages: int = 10) -> List[RawContent]:
        """å¾®åšæœç´¢å®ç°"""
        raw_data = await self.crawler.search_notes(
            keyword=" ".join(keywords),
            max_pages=max_pages
        )
        return [self._convert_to_raw_content(item) for item in raw_data]
    
    def _convert_to_raw_content(self, weibo_data: dict) -> RawContent:
        """å¾®åšæ•°æ®è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼"""
        return RawContent(
            content_id=weibo_data.get('id'),
            platform=self.platform_name,
            title=weibo_data.get('text', '')[:100],  # å¾®åšæ— æ ‡é¢˜ï¼Œæˆªå–å†…å®¹
            content=weibo_data.get('text', ''),
            author=weibo_data.get('user', {}).get('screen_name', ''),
            publish_time=self._parse_time(weibo_data.get('created_at')),
            url=f"https://weibo.com/{weibo_data.get('user', {}).get('id')}/{weibo_data.get('id')}",
            images=weibo_data.get('pic_urls', []),
            engagement={
                'reposts': weibo_data.get('reposts_count', 0),
                'comments': weibo_data.get('comments_count', 0),
                'likes': weibo_data.get('attitudes_count', 0)
            }
        )
```

### Phase 2: çŸ¥ä¹å¹³å°é›†æˆ (ä¼˜å…ˆçº§: é«˜)

**æ—¶é—´ä¼°ç®—**: 2-3å°æ—¶  
**æŠ€æœ¯å¤æ‚åº¦**: â­â­â­â­  
**ä¸šåŠ¡ä»·å€¼**: â­â­â­â­â­  

#### 3.2.1 å¼€å‘ä»»åŠ¡

1. **çŸ¥ä¹é€‚é…å™¨å¼€å‘**
   - æ–‡ä»¶: `src/crawler/platforms/zhihu_platform.py`
   - é—®ç­”æ ¼å¼å†…å®¹å¤„ç†
   - é•¿æ–‡æœ¬å†…å®¹ä¼˜åŒ–

2. **å†…å®¹ç±»å‹å¤„ç†**
   - é—®é¢˜-å›ç­”å…³è”
   - æ–‡ç« å†…å®¹æå–
   - æƒ³æ³•(åŠ¨æ€)å¤„ç†

3. **è´¨é‡è¿‡æ»¤å¢å¼º**
   - å†…å®¹é•¿åº¦è¿‡æ»¤
   - æŠ•èµ„ç›¸å…³æ€§åˆ¤æ–­
   - ä¸“ä¸šåº¦è¯„ä¼°

#### 3.2.2 å®ç°ç‰¹ç‚¹

- æ”¯æŒé—®é¢˜å’Œå›ç­”çš„å…³è”å¤„ç†
- é•¿æ–‡æœ¬å†…å®¹æ™ºèƒ½æˆªå–å’Œæ‘˜è¦
- ä¸“ä¸šæŠ•èµ„å†…å®¹ä¼˜å…ˆçº§æå‡
- ä½œè€…ä¸“ä¸šåº¦è¯„ä¼°æœºåˆ¶

### Phase 3: Bç«™å¹³å°é›†æˆ (ä¼˜å…ˆçº§: ä¸­)

**æ—¶é—´ä¼°ç®—**: 2-3å°æ—¶  
**æŠ€æœ¯å¤æ‚åº¦**: â­â­â­â­  
**ä¸šåŠ¡ä»·å€¼**: â­â­â­â­  

#### 3.3.1 å¼€å‘ä»»åŠ¡

1. **Bç«™é€‚é…å™¨å¼€å‘**
   - æ–‡ä»¶: `src/crawler/platforms/bilibili_platform.py`
   - è§†é¢‘å…ƒæ•°æ®æå–
   - å¤šåª’ä½“å†…å®¹æ”¯æŒ

2. **è§†é¢‘å†…å®¹å¤„ç†**
   - æ ‡é¢˜ã€æè¿°ã€æ ‡ç­¾æå–
   - ç¼©ç•¥å›¾URLè·å–
   - åˆ†åŒºç­›é€‰(ç§‘æŠ€/è´¢ç»)

3. **å†…å®¹ä¼˜åŒ–**
   - è§†é¢‘æ—¶é•¿è¿‡æ»¤
   - æ’­æ”¾é‡/ç‚¹èµæ•°æƒé‡
   - UPä¸»è®¤è¯çŠ¶æ€

#### 3.3.2 å®ç°ç‰¹ç‚¹

- ä¸“æ³¨è§†é¢‘æ ‡é¢˜å’Œæè¿°æ–‡æœ¬å†…å®¹
- æ”¯æŒä¸“æ æ–‡ç« çˆ¬å–
- åˆ†åŒºç­›é€‰æå‡å†…å®¹è´¨é‡
- å¤šåª’ä½“URLä¿å­˜ä½†ä¸ä¸‹è½½å†…å®¹

### Phase 4: ç³»ç»Ÿä¼˜åŒ–ä¸æ‰©å±•

**æ—¶é—´ä¼°ç®—**: 4-6å°æ—¶  
**æŠ€æœ¯å¤æ‚åº¦**: â­â­â­â­â­  
**ä¸šåŠ¡ä»·å€¼**: â­â­â­â­â­  

#### 3.4.1 å¤šå¹³å°åè°ƒ

1. **æ™ºèƒ½å¹³å°é€‰æ‹©**
   - å¹³å°æƒé‡é…ç½®
   - åŠ¨æ€å¹³å°è½®æ¢
   - è´Ÿè½½å‡è¡¡ç­–ç•¥

2. **è·¨å¹³å°å»é‡**
   - å†…å®¹æŒ‡çº¹è¯†åˆ«
   - ç›¸ä¼¼åº¦ç®—æ³•
   - é‡å¤å†…å®¹åˆå¹¶

3. **å¹¶å‘æ€§èƒ½ä¼˜åŒ–**
   - å¼‚æ­¥å¹¶å‘çˆ¬å–
   - é€Ÿç‡é™åˆ¶ç®¡ç†
   - è¿æ¥æ± ä¼˜åŒ–

#### 3.4.2 ç›‘æ§ä¸ç®¡ç†

1. **å¹³å°å¥åº·ç›‘æ§**
   - ç™»å½•çŠ¶æ€æ£€æŸ¥
   - çˆ¬å–æˆåŠŸç‡ç›‘æ§
   - é”™è¯¯ç‡æŠ¥è­¦

2. **åŠ¨æ€é…ç½®ç®¡ç†**
   - å¹³å°å¼€å…³æ§åˆ¶
   - å‚æ•°çƒ­æ›´æ–°
   - æ•…éšœè‡ªåŠ¨åˆ‡æ¢

---

## 4. æŠ€æœ¯å®ç°è§„èŒƒ

### 4.1 ä»£ç æ ‡å‡†

#### 4.1.1 æ–‡ä»¶å‘½åè§„èŒƒ

```
src/crawler/platforms/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ base.py                    # æŠ½è±¡åŸºç±»
â”œâ”€â”€ template_platform.py      # æ¨¡æ¿ä»£ç 
â”œâ”€â”€ xhs_platform.py          # ç°æœ‰å°çº¢ä¹¦å¹³å°
â”œâ”€â”€ weibo_platform.py        # å¾®åšå¹³å° [æ–°å¢]
â”œâ”€â”€ zhihu_platform.py        # çŸ¥ä¹å¹³å° [æ–°å¢]
â”œâ”€â”€ bilibili_platform.py     # Bç«™å¹³å° [æ–°å¢]
â”œâ”€â”€ douyin_platform.py       # æŠ–éŸ³å¹³å° [æ–°å¢]
â”œâ”€â”€ kuaishou_platform.py     # å¿«æ‰‹å¹³å° [æ–°å¢]
â””â”€â”€ tieba_platform.py        # è´´å§å¹³å° [æ–°å¢]
```

#### 4.1.2 ç±»å‘½åè§„èŒƒ

```python
# ç»Ÿä¸€å‘½åæ¨¡å¼: {Platform}Platform
class WeiboPlatform(AbstractPlatform)     # å¾®åš
class ZhihuPlatform(AbstractPlatform)     # çŸ¥ä¹
class BilibiliPlatform(AbstractPlatform)  # Bç«™
class DouyinPlatform(AbstractPlatform)    # æŠ–éŸ³
class KuaishouPlatform(AbstractPlatform)  # å¿«æ‰‹
class TiebaPlatform(AbstractPlatform)     # è´´å§
```

#### 4.1.3 æ–¹æ³•å®ç°æ ‡å‡†

```python
class PlatformTemplate(AbstractPlatform):
    """å¹³å°é€‚é…å™¨æ¨¡æ¿"""
    
    def __init__(self):
        self.platform_name = "platform_name"  # å¿…é¡»è®¾ç½®
        self.crawler = None                    # MediaCrawlerå®¢æˆ·ç«¯
        
    async def search(self, keywords: List[str], max_pages: int = 10) -> List[RawContent]:
        """æœç´¢æ¥å£å®ç° [å¿…é¡»å®ç°]"""
        pass
    
    async def login(self) -> bool:
        """ç™»å½•éªŒè¯ [å¿…é¡»å®ç°]"""
        pass
    
    def get_platform_name(self) -> str:
        """å¹³å°åç§° [å¿…é¡»å®ç°]"""
        return self.platform_name
    
    def _convert_to_raw_content(self, platform_data: dict) -> RawContent:
        """æ•°æ®è½¬æ¢æ–¹æ³• [å¿…é¡»å®ç°]"""
        pass
    
    def _parse_time(self, time_str: str) -> Optional[datetime]:
        """æ—¶é—´è§£æ [é€šç”¨æ–¹æ³•]"""
        pass
    
    def _extract_images(self, data: dict) -> List[str]:
        """å›¾ç‰‡æå– [é€šç”¨æ–¹æ³•]"""
        pass
```

### 4.2 é”™è¯¯å¤„ç†è§„èŒƒ

#### 4.2.1 å¼‚å¸¸åˆ†ç±»

```python
# src/crawler/exceptions.py

class PlatformException(Exception):
    """å¹³å°åŸºç¡€å¼‚å¸¸"""
    pass

class LoginFailedException(PlatformException):
    """ç™»å½•å¤±è´¥å¼‚å¸¸"""
    pass

class SearchFailedException(PlatformException):
    """æœç´¢å¤±è´¥å¼‚å¸¸"""
    pass

class RateLimitException(PlatformException):
    """é¢‘ç‡é™åˆ¶å¼‚å¸¸"""
    pass

class DataParseException(PlatformException):
    """æ•°æ®è§£æå¼‚å¸¸"""
    pass
```

#### 4.2.2 é”™è¯¯å¤„ç†æ¨¡å¼

```python
class PlatformTemplate(AbstractPlatform):
    
    async def search(self, keywords: List[str], max_pages: int = 10) -> List[RawContent]:
        try:
            # ç™»å½•æ£€æŸ¥
            if not await self.login():
                raise LoginFailedException(f"{self.platform_name} login failed")
            
            # æœç´¢æ‰§è¡Œ
            raw_data = await self._execute_search(keywords, max_pages)
            
            # æ•°æ®è½¬æ¢
            return [self._convert_to_raw_content(item) for item in raw_data]
            
        except LoginFailedException:
            logger.error(f"[{self.platform_name}] Login failed")
            raise
        except RateLimitException:
            logger.warning(f"[{self.platform_name}] Rate limit exceeded")
            raise
        except Exception as e:
            logger.error(f"[{self.platform_name}] Search failed: {str(e)}")
            raise SearchFailedException(f"Search failed: {str(e)}")
```

### 4.3 æ—¥å¿—è®°å½•æ ‡å‡†

#### 4.3.1 æ—¥å¿—æ ¼å¼

```python
import structlog

logger = structlog.get_logger(__name__)

# æ ‡å‡†æ—¥å¿—æ ¼å¼
logger.info(
    "platform_search_started",
    platform=self.platform_name,
    keywords=keywords,
    max_pages=max_pages
)

logger.info(
    "platform_search_completed",
    platform=self.platform_name,
    results_count=len(results),
    execution_time=execution_time
)
```

#### 4.3.2 å…³é”®èŠ‚ç‚¹æ—¥å¿—

```python
# ç™»å½•çŠ¶æ€
logger.info("platform_login_success", platform=self.platform_name)
logger.error("platform_login_failed", platform=self.platform_name, error=str(e))

# æœç´¢è¿‡ç¨‹
logger.info("search_request", platform=self.platform_name, keywords=keywords)
logger.info("search_response", platform=self.platform_name, count=len(results))

# æ•°æ®å¤„ç†
logger.info("data_conversion_start", platform=self.platform_name, raw_count=len(raw_data))
logger.info("data_conversion_complete", platform=self.platform_name, converted_count=len(results))

# å¼‚å¸¸æƒ…å†µ
logger.warning("rate_limit_hit", platform=self.platform_name, wait_time=60)
logger.error("search_failed", platform=self.platform_name, error=str(e))
```

---

## 5. é£é™©ç®¡ç†

### 5.1 æŠ€æœ¯é£é™©è¯„ä¼°

#### 5.1.1 é«˜é£é™©é¡¹

| é£é™©é¡¹ | å½±å“ç¨‹åº¦ | å‘ç”Ÿæ¦‚ç‡ | é£é™©ç­‰çº§ | ç¼“è§£ç­–ç•¥ |
|--------|----------|----------|----------|----------|
| å¹³å°åçˆ¬æœºåˆ¶å‡çº§ | é«˜ | ä¸­ | ğŸ”´ é«˜ | å¤šå¹³å°è½®æ¢ï¼Œé™ä½å•ä¸€å¹³å°ä¾èµ– |
| MediaCrawlerå…¼å®¹æ€§ | é«˜ | ä½ | ğŸŸ¡ ä¸­ | ç‰ˆæœ¬é”å®šï¼Œå……åˆ†æµ‹è¯• |
| ç™»å½•çŠ¶æ€å¤±æ•ˆ | ä¸­ | é«˜ | ğŸŸ¡ ä¸­ | è‡ªåŠ¨é‡ç™»å½•ï¼ŒçŠ¶æ€ç›‘æ§ |

#### 5.1.2 ä¸­é£é™©é¡¹

| é£é™©é¡¹ | å½±å“ç¨‹åº¦ | å‘ç”Ÿæ¦‚ç‡ | é£é™©ç­‰çº§ | ç¼“è§£ç­–ç•¥ |
|--------|----------|----------|----------|----------|
| æ•°æ®æ ¼å¼å˜æ›´ | ä¸­ | ä¸­ | ğŸŸ¡ ä¸­ | çµæ´»çš„æ•°æ®è§£æï¼Œå¼‚å¸¸å¤„ç† |
| æ€§èƒ½ç“¶é¢ˆ | ä¸­ | ä¸­ | ğŸŸ¡ ä¸­ | å¹¶å‘æ§åˆ¶ï¼Œç¼“å­˜ä¼˜åŒ– |
| é…ç½®å¤æ‚åº¦ | ä½ | é«˜ | ğŸŸ¢ ä½ | æ ‡å‡†åŒ–é…ç½®ï¼Œæ–‡æ¡£å®Œå–„ |

### 5.2 é£é™©ç¼“è§£ç­–ç•¥

#### 5.2.1 å¹³å°é£é™©ç¼“è§£

```python
# å¹³å°é™çº§ç­–ç•¥
class PlatformManager:
    def __init__(self):
        self.platform_status = {
            Platform.XHS: True,
            Platform.WEIBO: True,
            Platform.ZHIHU: True,
            Platform.BILIBILI: True
        }
        
    async def search_with_fallback(self, keywords: List[str]) -> List[RawContent]:
        """å¤šå¹³å°å®¹é”™æœç´¢"""
        results = []
        
        for platform, is_active in self.platform_status.items():
            if not is_active:
                continue
                
            try:
                platform_results = await self._search_single_platform(platform, keywords)
                results.extend(platform_results)
            except Exception as e:
                logger.warning(f"Platform {platform} failed: {str(e)}")
                # æš‚æ—¶ç¦ç”¨å¤±è´¥å¹³å°
                self.platform_status[platform] = False
                
        return results
```

#### 5.2.2 æ•°æ®è´¨é‡ä¿è¯

```python
# æ•°æ®éªŒè¯æœºåˆ¶
class DataValidator:
    @staticmethod
    def validate_raw_content(content: RawContent) -> bool:
        """éªŒè¯åŸå§‹å†…å®¹æ•°æ®å®Œæ•´æ€§"""
        required_fields = ['content_id', 'platform', 'content']
        
        for field in required_fields:
            if not getattr(content, field):
                return False
                
        # å†…å®¹é•¿åº¦æ£€æŸ¥
        if len(content.content) < 10:
            return False
            
        return True
    
    @staticmethod
    def sanitize_content(content: str) -> str:
        """å†…å®¹æ¸…ç†å’Œæ ‡å‡†åŒ–"""
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œæ ‡å‡†åŒ–æ ¼å¼
        import re
        
        # ç§»é™¤å¤šä½™ç©ºç™½
        content = re.sub(r'\s+', ' ', content)
        
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
        content = re.sub(r'[^\w\s\u4e00-\u9fff.,!?;:]', '', content)
        
        return content.strip()
```

### 5.3 ç›‘æ§é¢„è­¦æœºåˆ¶

#### 5.3.1 å¹³å°å¥åº·ç›‘æ§

```python
# å¥åº·æ£€æŸ¥
class PlatformHealthMonitor:
    def __init__(self):
        self.health_metrics = {}
        
    async def check_platform_health(self, platform: Platform) -> Dict[str, Any]:
        """å¹³å°å¥åº·æ£€æŸ¥"""
        try:
            platform_instance = PlatformFactory.create_platform(platform)
            
            # ç™»å½•æ£€æŸ¥
            login_success = await platform_instance.login()
            
            # æœç´¢æµ‹è¯•
            test_results = await platform_instance.search(["æµ‹è¯•"], max_pages=1)
            
            health_status = {
                'platform': platform.value,
                'login_status': login_success,
                'search_functional': len(test_results) > 0,
                'last_check': datetime.now(),
                'status': 'healthy' if login_success and len(test_results) > 0 else 'unhealthy'
            }
            
            self.health_metrics[platform] = health_status
            return health_status
            
        except Exception as e:
            error_status = {
                'platform': platform.value,
                'login_status': False,
                'search_functional': False,
                'last_check': datetime.now(),
                'status': 'error',
                'error': str(e)
            }
            
            self.health_metrics[platform] = error_status
            return error_status
```

#### 5.3.2 é¢„è­¦é˜ˆå€¼è®¾ç½®

```python
# é¢„è­¦é…ç½®
ALERT_THRESHOLDS = {
    'platform_failure_rate': 0.3,      # å¹³å°å¤±è´¥ç‡è¶…è¿‡30%
    'login_failure_count': 3,           # è¿ç»­ç™»å½•å¤±è´¥3æ¬¡
    'search_empty_rate': 0.5,          # æœç´¢ç©ºç»“æœç‡è¶…è¿‡50%
    'response_time_ms': 10000,         # å“åº”æ—¶é—´è¶…è¿‡10ç§’
    'error_rate_1h': 0.2               # 1å°æ—¶å†…é”™è¯¯ç‡è¶…è¿‡20%
}
```

---

## 6. æµ‹è¯•ç­–ç•¥

### 6.1 æµ‹è¯•é‡‘å­—å¡”

```
                    ğŸ”º E2Eæµ‹è¯•
                   /            \
                  /   é›†æˆæµ‹è¯•    \
                 /                \
                /     å•å…ƒæµ‹è¯•      \
               /____________________\
```

### 6.2 å•å…ƒæµ‹è¯•

#### 6.2.1 å¹³å°é€‚é…å™¨æµ‹è¯•

```python
# tests/test_platform_adapters.py

import pytest
from src.crawler.platforms.weibo_platform import WeiboPlatform
from src.crawler.models import RawContent

class TestWeiboPlatform:
    """å¾®åšå¹³å°æµ‹è¯•"""
    
    @pytest.fixture
    def weibo_platform(self):
        return WeiboPlatform()
    
    def test_platform_name(self, weibo_platform):
        """æµ‹è¯•å¹³å°åç§°"""
        assert weibo_platform.get_platform_name() == "weibo"
    
    @pytest.mark.asyncio
    async def test_search_functionality(self, weibo_platform):
        """æµ‹è¯•æœç´¢åŠŸèƒ½"""
        # Mockæ•°æ®
        mock_data = [
            {
                'id': '123456',
                'text': 'æµ‹è¯•å¾®åšå†…å®¹',
                'user': {'screen_name': 'æµ‹è¯•ç”¨æˆ·', 'id': 'user123'},
                'created_at': '2025-07-13T10:00:00',
                'reposts_count': 10,
                'comments_count': 5,
                'attitudes_count': 20
            }
        ]
        
        # æ¨¡æ‹Ÿæœç´¢
        with patch.object(weibo_platform.crawler, 'search_notes', return_value=mock_data):
            results = await weibo_platform.search(['TGE', 'Web3'])
            
        assert len(results) == 1
        assert isinstance(results[0], RawContent)
        assert results[0].platform == "weibo"
        assert results[0].content == "æµ‹è¯•å¾®åšå†…å®¹"
    
    def test_data_conversion(self, weibo_platform):
        """æµ‹è¯•æ•°æ®è½¬æ¢"""
        weibo_data = {
            'id': '123456',
            'text': 'æµ‹è¯•è½¬æ¢åŠŸèƒ½',
            'user': {'screen_name': 'æµ‹è¯•ç”¨æˆ·', 'id': 'user123'},
            'created_at': '2025-07-13T10:00:00',
            'pic_urls': ['http://example.com/pic1.jpg']
        }
        
        result = weibo_platform._convert_to_raw_content(weibo_data)
        
        assert result.content_id == '123456'
        assert result.platform == 'weibo'
        assert result.content == 'æµ‹è¯•è½¬æ¢åŠŸèƒ½'
        assert len(result.images) == 1
```

#### 6.2.2 å·¥å‚æ¨¡å¼æµ‹è¯•

```python
# tests/test_platform_factory.py

import pytest
from src.crawler.platform_factory import PlatformFactory
from src.crawler.platforms.base import Platform
from src.crawler.platforms.weibo_platform import WeiboPlatform

class TestPlatformFactory:
    """å¹³å°å·¥å‚æµ‹è¯•"""
    
    def test_create_weibo_platform(self):
        """æµ‹è¯•åˆ›å»ºå¾®åšå¹³å°"""
        platform = PlatformFactory.create_platform(Platform.WEIBO)
        assert isinstance(platform, WeiboPlatform)
        assert platform.get_platform_name() == "weibo"
    
    def test_get_available_platforms(self):
        """æµ‹è¯•è·å–å¯ç”¨å¹³å°åˆ—è¡¨"""
        platforms = PlatformFactory.get_available_platforms()
        assert Platform.WEIBO in platforms
        assert Platform.ZHIHU in platforms
        assert Platform.BILIBILI in platforms
    
    def test_invalid_platform(self):
        """æµ‹è¯•æ— æ•ˆå¹³å°å¤„ç†"""
        with pytest.raises(ValueError):
            PlatformFactory.create_platform("invalid_platform")
```

### 6.3 é›†æˆæµ‹è¯•

#### 6.3.1 å¤šå¹³å°é›†æˆæµ‹è¯•

```python
# tests/integration/test_multi_platform.py

import pytest
from src.crawler.crawler_manager import CrawlerManager
from src.crawler.platforms.base import Platform

class TestMultiPlatformIntegration:
    """å¤šå¹³å°é›†æˆæµ‹è¯•"""
    
    @pytest.fixture
    def crawler_manager(self):
        return CrawlerManager()
    
    @pytest.mark.asyncio
    async def test_multi_platform_search(self, crawler_manager):
        """æµ‹è¯•å¤šå¹³å°æœç´¢"""
        keywords = ["TGE", "Web3"]
        platforms = [Platform.XHS, Platform.WEIBO, Platform.ZHIHU]
        
        results = await crawler_manager.search_multi_platform(
            keywords=keywords,
            platforms=platforms,
            max_pages=2
        )
        
        # éªŒè¯ç»“æœåŒ…å«å¤šä¸ªå¹³å°çš„æ•°æ®
        platform_names = {result.platform for result in results}
        assert len(platform_names) >= 2  # è‡³å°‘2ä¸ªå¹³å°æœ‰æ•°æ®
        
        # éªŒè¯æ•°æ®æ ¼å¼ä¸€è‡´æ€§
        for result in results:
            assert hasattr(result, 'content_id')
            assert hasattr(result, 'platform')
            assert hasattr(result, 'content')
            assert result.platform in ['xhs', 'weibo', 'zhihu']
    
    @pytest.mark.asyncio
    async def test_platform_fallback(self, crawler_manager):
        """æµ‹è¯•å¹³å°é™çº§æœºåˆ¶"""
        # æ¨¡æ‹Ÿå¹³å°æ•…éšœ
        with patch('src.crawler.platforms.weibo_platform.WeiboPlatform.search', 
                  side_effect=Exception("Platform unavailable")):
            
            results = await crawler_manager.search_with_fallback(
                keywords=["TGE"],
                platforms=[Platform.WEIBO, Platform.XHS]
            )
            
            # åº”è¯¥åªæœ‰XHSå¹³å°çš„ç»“æœ
            platform_names = {result.platform for result in results}
            assert 'weibo' not in platform_names
            assert 'xhs' in platform_names
```

### 6.4 ç«¯åˆ°ç«¯æµ‹è¯•

#### 6.4.1 å®Œæ•´æµç¨‹æµ‹è¯•

```python
# tests/test_e2e_workflow.py

import pytest
from src.api.main import app
from fastapi.testclient import TestClient

class TestE2EWorkflow:
    """ç«¯åˆ°ç«¯å·¥ä½œæµæµ‹è¯•"""
    
    @pytest.fixture
    def client(self):
        return TestClient(app)
    
    def test_complete_tge_analysis_workflow(self, client):
        """æµ‹è¯•å®Œæ•´TGEåˆ†æå·¥ä½œæµ"""
        # 1. å¯åŠ¨å¤šå¹³å°çˆ¬å–
        crawl_response = client.post(
            "/api/v1/crawler/search",
            json={
                "keywords": ["TGE", "Web3"],
                "platforms": ["weibo", "zhihu"],
                "max_pages": 2
            }
        )
        assert crawl_response.status_code == 200
        
        # 2. è·å–çˆ¬å–ç»“æœ
        results_response = client.get("/api/v1/tge/latest?limit=10")
        assert results_response.status_code == 200
        
        data = results_response.json()
        assert len(data['items']) > 0
        
        # 3. éªŒè¯å¤šå¹³å°æ•°æ®
        platforms = {item['platform'] for item in data['items']}
        assert len(platforms) >= 2
        
        # 4. éªŒè¯AIåˆ†æç»“æœ
        for item in data['items']:
            if item.get('ai_summary'):
                assert 'sentiment' in item
                assert 'recommendation' in item
                assert 'confidence_score' in item
```

### 6.5 æ€§èƒ½æµ‹è¯•

#### 6.5.1 å¹¶å‘æµ‹è¯•

```python
# tests/test_performance.py

import pytest
import asyncio
import time
from src.crawler.crawler_manager import CrawlerManager

class TestPerformance:
    """æ€§èƒ½æµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_concurrent_platform_search(self):
        """æµ‹è¯•å¹¶å‘å¹³å°æœç´¢æ€§èƒ½"""
        crawler = CrawlerManager()
        keywords = ["TGE", "Web3"]
        
        start_time = time.time()
        
        # å¹¶å‘æœç´¢å¤šä¸ªå¹³å°
        tasks = [
            crawler.search_single_platform(Platform.WEIBO, keywords, 3),
            crawler.search_single_platform(Platform.ZHIHU, keywords, 3),
            crawler.search_single_platform(Platform.XHS, keywords, 3)
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        # æ€§èƒ½æ–­è¨€
        assert execution_time < 30  # æ€»æ‰§è¡Œæ—¶é—´åº”å°äº30ç§’
        
        # éªŒè¯å¹¶å‘ç»“æœ
        successful_results = [r for r in results if not isinstance(r, Exception)]
        assert len(successful_results) >= 2  # è‡³å°‘2ä¸ªå¹³å°æˆåŠŸ
    
    @pytest.mark.asyncio
    async def test_rate_limit_compliance(self):
        """æµ‹è¯•é€Ÿç‡é™åˆ¶éµå¾ª"""
        crawler = CrawlerManager()
        
        # è¿ç»­è¯·æ±‚æµ‹è¯•
        request_times = []
        for i in range(5):
            start = time.time()
            await crawler.search_single_platform(Platform.WEIBO, ["test"], 1)
            request_times.append(time.time() - start)
        
        # éªŒè¯è¯·æ±‚é—´éš”
        intervals = [request_times[i+1] - request_times[i] for i in range(len(request_times)-1)]
        min_interval = min(intervals)
        
        # ç¡®ä¿éµå¾ªæœ€å°é—´éš”(æ ¹æ®å¹³å°é…ç½®)
        assert min_interval >= 1.0  # æœ€å°1ç§’é—´éš”
```

---

## 7. é¡¹ç›®ç®¡ç†

### 7.1 å¼€å‘æ—¶é—´çº¿

#### 7.1.1 æ€»ä½“è§„åˆ’

```
é¡¹ç›®æ—¶é—´çº¿ (é¢„è®¡14-20å°æ—¶æ€»å·¥ä½œé‡)

Week 1: Phase 1 - å¾®åšå¹³å°é›†æˆ
â”œâ”€â”€ Day 1: å¾®åšé€‚é…å™¨å¼€å‘ (2-3å°æ—¶)
â”œâ”€â”€ Day 2: é…ç½®é›†æˆå’Œæµ‹è¯• (1-2å°æ—¶)
â””â”€â”€ Day 3: é—®é¢˜ä¿®å¤å’Œä¼˜åŒ– (1å°æ—¶)

Week 2: Phase 2 - çŸ¥ä¹å¹³å°é›†æˆ  
â”œâ”€â”€ Day 1: çŸ¥ä¹é€‚é…å™¨å¼€å‘ (2-3å°æ—¶)
â”œâ”€â”€ Day 2: é•¿æ–‡æœ¬å¤„ç†ä¼˜åŒ– (1-2å°æ—¶)
â””â”€â”€ Day 3: æµ‹è¯•éªŒè¯ (1å°æ—¶)

Week 3: Phase 3 - Bç«™å¹³å°é›†æˆ
â”œâ”€â”€ Day 1: Bç«™é€‚é…å™¨å¼€å‘ (2-3å°æ—¶)
â”œâ”€â”€ Day 2: å¤šåª’ä½“å¤„ç† (1-2å°æ—¶)
â””â”€â”€ Day 3: é›†æˆæµ‹è¯• (1å°æ—¶)

Week 4: Phase 4 - ç³»ç»Ÿä¼˜åŒ–
â”œâ”€â”€ Day 1-2: å¤šå¹³å°åè°ƒå¼€å‘ (3-4å°æ—¶)
â”œâ”€â”€ Day 3-4: ç›‘æ§å’Œç®¡ç†åŠŸèƒ½ (2-3å°æ—¶)
â””â”€â”€ Day 5: å…¨é¢æµ‹è¯•å’Œæ–‡æ¡£ (2å°æ—¶)
```

#### 7.1.2 å…³é”®é‡Œç¨‹ç¢‘

| é‡Œç¨‹ç¢‘ | äº¤ä»˜ç‰© | éªŒæ”¶æ ‡å‡† | æ—¶é—´èŠ‚ç‚¹ |
|--------|--------|----------|----------|
| M1: å¾®åšé›†æˆå®Œæˆ | WeiboPlatform + æµ‹è¯• | å¾®åšæœç´¢æ­£å¸¸ï¼Œæ•°æ®æ ¼å¼æ­£ç¡® | Week 1 |
| M2: çŸ¥ä¹é›†æˆå®Œæˆ | ZhihuPlatform + æµ‹è¯• | çŸ¥ä¹å†…å®¹è§£ææ­£ç¡®ï¼Œé•¿æ–‡æœ¬å¤„ç† | Week 2 |
| M3: Bç«™é›†æˆå®Œæˆ | BilibiliPlatform + æµ‹è¯• | è§†é¢‘å†…å®¹å…ƒæ•°æ®æå–æ­£ç¡® | Week 3 |
| M4: ç³»ç»Ÿä¼˜åŒ–å®Œæˆ | å¤šå¹³å°åè°ƒ + ç›‘æ§ | å¤šå¹³å°å¹¶å‘ç¨³å®šï¼Œç›‘æ§æ­£å¸¸ | Week 4 |

### 7.2 è´¨é‡é—¨æ§

#### 7.2.1 ä»£ç è´¨é‡æ ‡å‡†

```bash
# è´¨é‡æ£€æŸ¥å‘½ä»¤
# ä»£ç æ ¼å¼åŒ–
black src/ tests/
isort src/ tests/

# é™æ€åˆ†æ
flake8 src/ tests/
mypy src/

# æµ‹è¯•è¦†ç›–ç‡
pytest tests/ --cov=src --cov-report=html --cov-fail-under=80

# æ€§èƒ½æµ‹è¯•
pytest tests/test_performance.py -v
```

#### 7.2.2 é›†æˆæ ‡å‡†

æ¯ä¸ªå¹³å°é›†æˆå¿…é¡»é€šè¿‡ä»¥ä¸‹æ£€æŸ¥ï¼š

1. **åŠŸèƒ½æµ‹è¯•** âœ…
   - ç™»å½•æˆåŠŸ
   - æœç´¢è¿”å›ç»“æœ
   - æ•°æ®è½¬æ¢æ­£ç¡®

2. **è´¨é‡æµ‹è¯•** âœ…
   - å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 80%
   - é›†æˆæµ‹è¯•é€šè¿‡
   - æ€§èƒ½æµ‹è¯•é€šè¿‡

3. **å®‰å…¨æµ‹è¯•** âœ…
   - æ— æ•æ„Ÿä¿¡æ¯æ³„éœ²
   - é”™è¯¯å¤„ç†å®Œå–„
   - æ—¥å¿—è®°å½•è§„èŒƒ

4. **å…¼å®¹æ€§æµ‹è¯•** âœ…
   - ç°æœ‰åŠŸèƒ½æ— å½±å“
   - APIå‘åå…¼å®¹
   - é…ç½®å‘ä¸‹å…¼å®¹

### 7.3 èµ„æºåˆ†é…

#### 7.3.1 å¼€å‘èµ„æº

```
æ ¸å¿ƒå¼€å‘èµ„æºåˆ†é…:
â”œâ”€â”€ å¹³å°é€‚é…å™¨å¼€å‘: 60% (12å°æ—¶)
â”œâ”€â”€ ç³»ç»Ÿé›†æˆä¼˜åŒ–: 25% (5å°æ—¶)  
â”œâ”€â”€ æµ‹è¯•å’Œæ–‡æ¡£: 10% (2å°æ—¶)
â””â”€â”€ é—®é¢˜ä¿®å¤ç¼“å†²: 5% (1å°æ—¶)
```

#### 7.3.2 æŠ€æœ¯ä¾èµ–

**å¿…éœ€ä¾èµ–:**
- MediaCrawler (å·²å…·å¤‡)
- FastAPI (å·²å…·å¤‡)  
- SQLAlchemy (å·²å…·å¤‡)
- pytest (å·²å…·å¤‡)

**æ–°å¢ä¾èµ–:**
- æ— éœ€æ–°å¢ç¬¬ä¸‰æ–¹ä¾èµ–
- åˆ©ç”¨ç°æœ‰æŠ€æœ¯æ ˆ

#### 7.3.3 ç¯å¢ƒè¦æ±‚

**å¼€å‘ç¯å¢ƒ:**
- Python 3.9+
- MySQL 5.7+
- MediaCrawler è¿è¡Œç¯å¢ƒ

**æµ‹è¯•ç¯å¢ƒ:**
- ç‹¬ç«‹æµ‹è¯•æ•°æ®åº“
- æ¨¡æ‹Ÿç™»å½•å‡­è¯
- ç½‘ç»œè¿æ¥(ç”¨äºçœŸå®å¹³å°æµ‹è¯•)

---

## 8. é™„å½•

### 8.1 é…ç½®æ¨¡æ¿

#### 8.1.1 .env é…ç½®æ¨¡æ¿

```bash
# ==============================================
# å¤šå¹³å°é…ç½®æ¨¡æ¿
# ==============================================

# ç°æœ‰é…ç½® (ä¿æŒä¸å˜)
AI_API_KEY=your_ai_api_key_here
MYSQL_HOST=localhost
MYSQL_PORT=3306
MYSQL_USER=your_username
MYSQL_PASSWORD=your_password
MYSQL_DATABASE=web3_tge_monitor

# MediaCrawlerè·¯å¾„
MEDIACRAWLER_PATH=../MediaCrawler

# åŸºç¡€é…ç½®
WEB3_KEYWORDS=TGE,Token Generation Event,ä»£å¸ç”Ÿæˆ,å¸å®‰,æ¬§æ˜“,ç«å¸
CRAWLER_MAX_PAGES=10
DATA_RETENTION_DAYS=30

# ==============================================
# æ–°å¢å¤šå¹³å°é…ç½®
# ==============================================

# å¾®åšå¹³å° (Weibo)
WEIBO_COOKIE=""
WEIBO_SEARCH_TYPE="ç»¼åˆ"  # ç»¼åˆ/å®æ—¶/çƒ­é—¨
WEIBO_MAX_PAGES=10
WEIBO_RATE_LIMIT=60
WEIBO_ENABLED=true

# çŸ¥ä¹å¹³å° (Zhihu)  
ZHIHU_COOKIE=""
ZHIHU_SEARCH_TYPE="ç»¼åˆ"  # ç»¼åˆ/é—®é¢˜/å›ç­”/æ–‡ç« 
ZHIHU_MAX_PAGES=10
ZHIHU_RATE_LIMIT=60
ZHIHU_ENABLED=true

# Bç«™å¹³å° (Bilibili)
BILIBILI_COOKIE=""
BILIBILI_SEARCH_TYPE="è§†é¢‘"  # è§†é¢‘/ä¸“æ /ç”¨æˆ·
BILIBILI_MAX_PAGES=10
BILIBILI_RATE_LIMIT=60
BILIBILI_ENABLED=true

# æŠ–éŸ³å¹³å° (Douyin)
DOUYIN_COOKIE=""
DOUYIN_MAX_PAGES=10
DOUYIN_RATE_LIMIT=60
DOUYIN_ENABLED=false  # é»˜è®¤å…³é—­

# å¿«æ‰‹å¹³å° (Kuaishou)
KUAISHOU_COOKIE=""
KUAISHOU_MAX_PAGES=10
KUAISHOU_RATE_LIMIT=60
KUAISHOU_ENABLED=false  # é»˜è®¤å…³é—­

# è´´å§å¹³å° (Tieba)
TIEBA_COOKIE=""
TIEBA_MAX_PAGES=10
TIEBA_RATE_LIMIT=60
TIEBA_ENABLED=false  # é»˜è®¤å…³é—­

# ==============================================
# å¤šå¹³å°é«˜çº§é…ç½®
# ==============================================

# å¹³å°ä¼˜å…ˆçº§ (1-10, æ•°å­—è¶Šå¤§ä¼˜å…ˆçº§è¶Šé«˜)
PLATFORM_PRIORITY_XHS=10
PLATFORM_PRIORITY_WEIBO=9
PLATFORM_PRIORITY_ZHIHU=8
PLATFORM_PRIORITY_BILIBILI=7
PLATFORM_PRIORITY_DOUYIN=5
PLATFORM_PRIORITY_KUAISHOU=4
PLATFORM_PRIORITY_TIEBA=3

# å¹¶å‘æ§åˆ¶
MAX_CONCURRENT_PLATFORMS=3
PLATFORM_TIMEOUT_SECONDS=30

# é‡è¯•ç­–ç•¥
MAX_RETRY_ATTEMPTS=3
RETRY_DELAY_SECONDS=5

# å¥åº·æ£€æŸ¥
HEALTH_CHECK_INTERVAL=300  # 5åˆ†é’Ÿ
PLATFORM_FAILURE_THRESHOLD=0.3
```

#### 8.1.2 å¹³å°é…ç½® JSON æ¨¡æ¿

```json
{
  "platforms": {
    "weibo": {
      "display_name": "å¾®åš",
      "enabled": true,
      "search_types": ["ç»¼åˆ", "å®æ—¶", "çƒ­é—¨"],
      "content_types": ["å¾®åš", "æ–‡ç« "],
      "rate_limit": 60,
      "max_pages_default": 10,
      "timeout": 30,
      "retry_attempts": 3,
      "priority": 9,
      "features": {
        "support_images": true,
        "support_videos": true,
        "support_comments": true,
        "support_reposts": true
      }
    },
    "zhihu": {
      "display_name": "çŸ¥ä¹",
      "enabled": true,
      "search_types": ["ç»¼åˆ", "é—®é¢˜", "å›ç­”", "æ–‡ç« "],
      "content_types": ["é—®é¢˜", "å›ç­”", "æ–‡ç« ", "æƒ³æ³•"],
      "rate_limit": 60,
      "max_pages_default": 10,
      "timeout": 30,
      "retry_attempts": 3,
      "priority": 8,
      "features": {
        "support_images": true,
        "support_videos": false,
        "support_comments": true,
        "support_long_content": true
      }
    },
    "bilibili": {
      "display_name": "å“”å“©å“”å“©",
      "enabled": true,
      "search_types": ["è§†é¢‘", "ä¸“æ ", "ç”¨æˆ·"],
      "content_types": ["è§†é¢‘", "ä¸“æ "],
      "categories": ["ç§‘æŠ€", "è´¢ç»", "çŸ¥è¯†"],
      "rate_limit": 60,
      "max_pages_default": 10,
      "timeout": 30,
      "retry_attempts": 3,
      "priority": 7,
      "features": {
        "support_images": true,
        "support_videos": true,
        "support_thumbnails": true,
        "support_duration": true
      }
    }
  }
}
```

### 8.2 å¼€å‘å·¥å…·

#### 8.2.1 å¿«é€Ÿå¼€å‘è„šæœ¬

```bash
#!/bin/bash
# scripts/create_platform.sh
# å¿«é€Ÿåˆ›å»ºæ–°å¹³å°é€‚é…å™¨è„šæœ¬

PLATFORM_NAME=$1

if [ -z "$PLATFORM_NAME" ]; then
    echo "Usage: $0 <platform_name>"
    echo "Example: $0 weibo"
    exit 1
fi

# åˆ›å»ºå¹³å°é€‚é…å™¨æ–‡ä»¶
cp src/crawler/platforms/template_platform.py src/crawler/platforms/${PLATFORM_NAME}_platform.py

# æ›¿æ¢æ¨¡æ¿ä¸­çš„å ä½ç¬¦
sed -i "s/TemplatePlatform/${PLATFORM_NAME^}Platform/g" src/crawler/platforms/${PLATFORM_NAME}_platform.py
sed -i "s/template_platform/${PLATFORM_NAME}_platform/g" src/crawler/platforms/${PLATFORM_NAME}_platform.py
sed -i "s/\"template\"/\"${PLATFORM_NAME}\"/g" src/crawler/platforms/${PLATFORM_NAME}_platform.py

# åˆ›å»ºæµ‹è¯•æ–‡ä»¶
cp tests/template_test_platform.py tests/test_${PLATFORM_NAME}_platform.py
sed -i "s/TemplatePlatform/${PLATFORM_NAME^}Platform/g" tests/test_${PLATFORM_NAME}_platform.py
sed -i "s/template_platform/${PLATFORM_NAME}_platform/g" tests/test_${PLATFORM_NAME}_platform.py

echo "Created platform adapter: src/crawler/platforms/${PLATFORM_NAME}_platform.py"
echo "Created test file: tests/test_${PLATFORM_NAME}_platform.py"
echo ""
echo "Next steps:"
echo "1. Implement the platform-specific methods in ${PLATFORM_NAME}_platform.py"
echo "2. Add ${PLATFORM_NAME.upper()} to Platform enum in src/crawler/platforms/base.py"
echo "3. Register the platform in src/crawler/platform_factory.py"
echo "4. Add configuration variables to .env"
echo "5. Run tests: pytest tests/test_${PLATFORM_NAME}_platform.py -v"
```

#### 8.2.2 æµ‹è¯•åŠ©æ‰‹è„šæœ¬

```bash
#!/bin/bash
# scripts/test_platform.sh
# å¹³å°åŠŸèƒ½æµ‹è¯•è„šæœ¬

PLATFORM_NAME=$1

if [ -z "$PLATFORM_NAME" ]; then
    echo "Usage: $0 <platform_name>"
    echo "Example: $0 weibo"
    exit 1
fi

echo "Testing ${PLATFORM_NAME} platform..."

# è¿è¡Œå•å…ƒæµ‹è¯•
echo "1. Running unit tests..."
pytest tests/test_${PLATFORM_NAME}_platform.py -v

# è¿è¡Œé›†æˆæµ‹è¯•
echo "2. Running integration tests..."
pytest tests/integration/test_${PLATFORM_NAME}_integration.py -v

# è¿è¡Œä»£ç è´¨é‡æ£€æŸ¥
echo "3. Running code quality checks..."
flake8 src/crawler/platforms/${PLATFORM_NAME}_platform.py
mypy src/crawler/platforms/${PLATFORM_NAME}_platform.py

# è¿è¡ŒçœŸå®æœç´¢æµ‹è¯• (å¯é€‰)
echo "4. Running real search test (optional)..."
python3 -c "
import asyncio
import sys
sys.path.append('src')
from crawler.platform_factory import PlatformFactory
from crawler.platforms.base import Platform

async def test_real_search():
    try:
        platform = PlatformFactory.create_platform(Platform.${PLATFORM_NAME.upper()})
        results = await platform.search(['æµ‹è¯•'], max_pages=1)
        print(f'âœ… Real search test passed: {len(results)} results')
    except Exception as e:
        print(f'âŒ Real search test failed: {str(e)}')

asyncio.run(test_real_search())
"

echo "Platform testing completed!"
```

#### 8.2.3 é…ç½®éªŒè¯è„šæœ¬

```bash
#!/bin/bash
# scripts/validate_config.sh
# é…ç½®éªŒè¯è„šæœ¬

echo "Validating multi-platform configuration..."

# æ£€æŸ¥å¿…éœ€çš„ç¯å¢ƒå˜é‡
required_vars=(
    "AI_API_KEY"
    "MYSQL_HOST"
    "MYSQL_DATABASE"
    "MEDIACRAWLER_PATH"
)

missing_vars=()

for var in "${required_vars[@]}"; do
    if [ -z "${!var}" ]; then
        missing_vars+=("$var")
    fi
done

if [ ${#missing_vars[@]} -gt 0 ]; then
    echo "âŒ Missing required environment variables:"
    printf '%s\n' "${missing_vars[@]}"
    exit 1
fi

# æ£€æŸ¥MediaCrawlerè·¯å¾„
if [ ! -d "$MEDIACRAWLER_PATH" ]; then
    echo "âŒ MediaCrawler path not found: $MEDIACRAWLER_PATH"
    exit 1
fi

# æ£€æŸ¥æ•°æ®åº“è¿æ¥
echo "Checking database connection..."
python3 -c "
import sys
sys.path.append('src')
import asyncio
from database.database import check_database_connection

async def check():
    try:
        await check_database_connection()
        print('âœ… Database connection successful')
        return True
    except Exception as e:
        print(f'âŒ Database connection failed: {str(e)}')
        return False

result = asyncio.run(check())
sys.exit(0 if result else 1)
"

if [ $? -ne 0 ]; then
    echo "Database connection check failed!"
    exit 1
fi

# æ£€æŸ¥å¹³å°é…ç½®
enabled_platforms=()

platforms=("WEIBO" "ZHIHU" "BILIBILI" "DOUYIN" "KUAISHOU" "TIEBA")

for platform in "${platforms[@]}"; do
    enabled_var="${platform}_ENABLED"
    if [ "${!enabled_var}" = "true" ]; then
        enabled_platforms+=("$platform")
        
        # æ£€æŸ¥Cookieé…ç½®
        cookie_var="${platform}_COOKIE"
        if [ -z "${!cookie_var}" ]; then
            echo "âš ï¸  Warning: ${platform} is enabled but cookie is not configured"
        fi
    fi
done

echo "âœ… Configuration validation completed!"
echo "Enabled platforms: ${enabled_platforms[*]}"
echo "Total enabled platforms: ${#enabled_platforms[@]}"

if [ ${#enabled_platforms[@]} -eq 0 ]; then
    echo "âš ï¸  Warning: No platforms are enabled!"
fi
```

### 8.3 æ•…éšœæ’é™¤æŒ‡å—

#### 8.3.1 å¸¸è§é—®é¢˜è§£å†³

**é—®é¢˜1: å¹³å°ç™»å½•å¤±è´¥**
```
ç—‡çŠ¶: LoginFailedException
åŸå› : Cookieè¿‡æœŸæˆ–æ— æ•ˆ
è§£å†³: 
1. æ›´æ–°å¹³å°Cookie
2. æ£€æŸ¥è´¦å·çŠ¶æ€
3. é‡æ–°è·å–ç™»å½•å‡­è¯
```

**é—®é¢˜2: æœç´¢è¿”å›ç©ºç»“æœ**
```
ç—‡çŠ¶: æœç´¢æˆåŠŸä½†ç»“æœä¸ºç©º
åŸå› : å…³é”®è¯è¿‡æ»¤æˆ–å¹³å°é™åˆ¶
è§£å†³:
1. è°ƒæ•´æœç´¢å…³é”®è¯
2. æ£€æŸ¥å¹³å°æœç´¢ç±»å‹é…ç½®
3. éªŒè¯å†…å®¹è¿‡æ»¤é€»è¾‘
```

**é—®é¢˜3: æ•°æ®è§£æå¼‚å¸¸**
```
ç—‡çŠ¶: DataParseException
åŸå› : å¹³å°æ•°æ®æ ¼å¼å˜æ›´
è§£å†³:
1. æ£€æŸ¥å¹³å°è¿”å›æ•°æ®ç»“æ„
2. æ›´æ–°æ•°æ®è§£æé€»è¾‘
3. æ·»åŠ å®¹é”™å¤„ç†
```

**é—®é¢˜4: é¢‘ç‡é™åˆ¶è§¦å‘**
```
ç—‡çŠ¶: RateLimitException
åŸå› : è¯·æ±‚è¿‡äºé¢‘ç¹
è§£å†³:
1. å¢åŠ è¯·æ±‚é—´éš”
2. æ£€æŸ¥é€Ÿç‡é™åˆ¶é…ç½®
3. å®æ–½æŒ‡æ•°é€€é¿ç­–ç•¥
```

#### 8.3.2 è°ƒè¯•å·¥å…·

```python
# debug/platform_debugger.py
# å¹³å°è°ƒè¯•å·¥å…·

import asyncio
import json
from src.crawler.platform_factory import PlatformFactory
from src.crawler.platforms.base import Platform

class PlatformDebugger:
    """å¹³å°è°ƒè¯•å·¥å…·"""
    
    @staticmethod
    async def debug_platform(platform_name: str, keywords: list):
        """è°ƒè¯•ç‰¹å®šå¹³å°"""
        try:
            platform_enum = Platform(platform_name)
            platform = PlatformFactory.create_platform(platform_enum)
            
            print(f"ğŸ” Debugging platform: {platform_name}")
            
            # 1. ç™»å½•æµ‹è¯•
            print("1. Testing login...")
            login_result = await platform.login()
            print(f"   Login result: {'âœ… Success' if login_result else 'âŒ Failed'}")
            
            # 2. æœç´¢æµ‹è¯•
            print("2. Testing search...")
            search_results = await platform.search(keywords, max_pages=1)
            print(f"   Search results: {len(search_results)} items")
            
            # 3. æ•°æ®æ ·æœ¬
            if search_results:
                print("3. Sample data:")
                sample = search_results[0]
                print(f"   Content ID: {sample.content_id}")
                print(f"   Platform: {sample.platform}")
                print(f"   Content: {sample.content[:100]}...")
                print(f"   Author: {sample.author}")
                print(f"   Images: {len(sample.images)}")
                
            return True
            
        except Exception as e:
            print(f"âŒ Debug failed: {str(e)}")
            return False

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    asyncio.run(PlatformDebugger.debug_platform("weibo", ["TGE", "Web3"]))
```

### 8.4 æ€§èƒ½ä¼˜åŒ–å»ºè®®

#### 8.4.1 å¹¶å‘ä¼˜åŒ–

```python
# å¹¶å‘æœç´¢ä¼˜åŒ–
async def optimized_multi_platform_search(keywords: List[str]) -> List[RawContent]:
    """ä¼˜åŒ–çš„å¤šå¹³å°å¹¶å‘æœç´¢"""
    
    # 1. æŒ‰ä¼˜å…ˆçº§åˆ†ç»„
    high_priority = [Platform.XHS, Platform.WEIBO, Platform.ZHIHU]
    low_priority = [Platform.BILIBILI, Platform.DOUYIN]
    
    results = []
    
    # 2. é«˜ä¼˜å…ˆçº§å¹³å°å¹¶å‘æ‰§è¡Œ
    high_priority_tasks = [
        search_single_platform(platform, keywords, 5)
        for platform in high_priority
    ]
    
    high_results = await asyncio.gather(*high_priority_tasks, return_exceptions=True)
    results.extend([r for r in high_results if not isinstance(r, Exception)])
    
    # 3. å¦‚æœé«˜ä¼˜å…ˆçº§ç»“æœä¸è¶³ï¼Œæ‰§è¡Œä½ä¼˜å…ˆçº§
    if len(results) < 50:  # ç›®æ ‡ç»“æœæ•°é‡
        low_priority_tasks = [
            search_single_platform(platform, keywords, 3)
            for platform in low_priority
        ]
        
        low_results = await asyncio.gather(*low_priority_tasks, return_exceptions=True)
        results.extend([r for r in low_results if not isinstance(r, Exception)])
    
    return results
```

#### 8.4.2 ç¼“å­˜ç­–ç•¥

```python
# å¹³å°ç»“æœç¼“å­˜
from functools import lru_cache
import hashlib

class PlatformCache:
    """å¹³å°æœç´¢ç»“æœç¼“å­˜"""
    
    def __init__(self, ttl=3600):  # 1å°æ—¶ç¼“å­˜
        self.cache = {}
        self.ttl = ttl
    
    def _generate_key(self, platform: str, keywords: List[str], max_pages: int) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        content = f"{platform}:{':'.join(sorted(keywords))}:{max_pages}"
        return hashlib.md5(content.encode()).hexdigest()
    
    async def get_or_search(self, platform, keywords, max_pages):
        """è·å–ç¼“å­˜æˆ–æ‰§è¡Œæœç´¢"""
        cache_key = self._generate_key(platform.value, keywords, max_pages)
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self.cache:
            cached_data, timestamp = self.cache[cache_key]
            if time.time() - timestamp < self.ttl:
                return cached_data
        
        # æ‰§è¡Œæœç´¢
        platform_instance = PlatformFactory.create_platform(platform)
        results = await platform_instance.search(keywords, max_pages)
        
        # æ›´æ–°ç¼“å­˜
        self.cache[cache_key] = (results, time.time())
        
        return results
```

---

## ç»“è®º

æœ¬å¼€å‘è®¡åˆ’æ–‡æ¡£æä¾›äº†Web3 TGE Monitorç³»ç»Ÿå¤šå¹³å°é›†æˆçš„å®Œæ•´å®æ–½æ–¹æ¡ˆã€‚é€šè¿‡åˆ†é˜¶æ®µçš„æ¸è¿›å¼å¼€å‘ï¼Œæˆ‘ä»¬å°†åœ¨ä¿æŒç³»ç»Ÿç¨³å®šæ€§çš„å‰æä¸‹ï¼Œå°†æ•°æ®è¦†ç›–é¢ä»å•ä¸€å°çº¢ä¹¦å¹³å°æ‰©å±•åˆ°6ä¸ªä¸»æµç¤¾äº¤åª’ä½“å¹³å°ã€‚

**æ ¸å¿ƒä¼˜åŠ¿:**
- ğŸš€ é›¶é‡æ„é£é™© - åŸºäºç°æœ‰ä¼˜ç§€æ¶æ„
- ğŸ“ˆ 500%+ æ•°æ®è¦†ç›–æå‡
- ğŸ”’ æ¸è¿›å¼å®æ–½ç­–ç•¥
- ğŸ›¡ï¸ å®Œå–„çš„é£é™©æ§åˆ¶
- ğŸ§ª å…¨é¢çš„æµ‹è¯•è¦†ç›–

**é¢„æœŸæ”¶ç›Š:**
- æ›´å…¨é¢çš„Web3/TGEä¿¡æ¯ç›‘æ§
- æ›´å‡†ç¡®çš„å¸‚åœºè¶‹åŠ¿åˆ†æ  
- æ›´å¼ºçš„ç³»ç»Ÿå¯é æ€§å’Œæ‰©å±•æ€§
- æ›´ä¸°å¯Œçš„AIåˆ†ææ•°æ®æº

è¯¥è®¡åˆ’é¢„è®¡æ€»å¼€å‘æ—¶é—´14-20å°æ—¶ï¼Œåˆ†4ä¸ªé˜¶æ®µå®æ–½ï¼Œæ¯ä¸ªé˜¶æ®µéƒ½æœ‰æ˜ç¡®çš„äº¤ä»˜ç‰©å’ŒéªŒæ”¶æ ‡å‡†ã€‚é€šè¿‡éµå¾ªæœ¬æ–‡æ¡£çš„æŠ€æœ¯è§„èŒƒå’Œæœ€ä½³å®è·µï¼Œå¯ä»¥ç¡®ä¿é¡¹ç›®çš„é«˜è´¨é‡äº¤ä»˜ã€‚

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025-07-13  
**ç»´æŠ¤äººå‘˜**: Web3 TGE Monitorå¼€å‘å›¢é˜Ÿ

*æœ¬æ–‡æ¡£å°†éšç€é¡¹ç›®è¿›å±•æŒç»­æ›´æ–°å’Œå®Œå–„ã€‚*