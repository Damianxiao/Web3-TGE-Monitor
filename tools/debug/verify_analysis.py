#!/usr/bin/env python3
"""
éªŒè¯ç”¨æˆ·åˆ†æï¼šQRç ç™»å½•æˆåŠŸä½†å†…å®¹è¢«è¿‡æ»¤çš„é—®é¢˜
"""
import asyncio
import json
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / "src"))
sys.path.insert(0, str(project_root / "mediacrawler"))

async def verify_content_filtering():
    """éªŒè¯å†…å®¹è¿‡æ»¤é—®é¢˜"""
    
    print("ğŸ” éªŒè¯å†…å®¹è¿‡æ»¤åˆ†æ")
    print("="*60)
    
    # åˆ‡æ¢åˆ°mediacrawlerç›®å½•
    original_cwd = os.getcwd()
    mediacrawler_path = project_root / "mediacrawler"
    
    try:
        os.chdir(mediacrawler_path)
        
        # å¯¼å…¥å¿…è¦æ¨¡å—
        from media_platform.xhs.core import XiaoHongShuCrawler
        from media_platform.xhs.client import XiaoHongShuClient
        from media_platform.xhs.help import get_search_id
        from media_platform.xhs.field import SearchSortType, SearchNoteType
        from playwright.async_api import async_playwright
        import config
        
        print(f"ğŸ“ å½“å‰é…ç½®:")
        print(f"   - LOGIN_TYPE: {config.LOGIN_TYPE}")
        print(f"   - HEADLESS: {config.HEADLESS}")
        
        # åˆ›å»ºçˆ¬è™«å®ä¾‹
        crawler = XiaoHongShuCrawler()
        
        async with async_playwright() as playwright:
            print(f"\nğŸš€ å¯åŠ¨æµè§ˆå™¨...")
            
            # å¯åŠ¨æµè§ˆå™¨
            chromium = playwright.chromium
            browser_context = await crawler.launch_browser(
                chromium, None, crawler.user_agent, headless=config.HEADLESS
            )
            
            # è®¾ç½®æµè§ˆå™¨ä¸Šä¸‹æ–‡
            crawler.browser_context = browser_context
            
            # æ·»åŠ è„šæœ¬å’ŒCookie
            await browser_context.add_init_script(path="libs/stealth.min.js")
            
            # åˆ›å»ºé¡µé¢
            context_page = await browser_context.new_page()
            await context_page.goto(crawler.index_url)
            crawler.context_page = context_page
            
            print("âœ… æµè§ˆå™¨å¯åŠ¨æˆåŠŸ")
            
            # åˆ›å»ºXHSå®¢æˆ·ç«¯
            print(f"\nğŸ”§ åˆ›å»ºXHSå®¢æˆ·ç«¯...")
            client = await crawler.create_xhs_client(None)
            
            print("âœ… XHSå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
            
            # æµ‹è¯•ä¸åŒçš„æœç´¢å‚æ•°ç»„åˆ
            test_cases = [
                {
                    "name": "åŸºç¡€æœç´¢-ç¾é£Ÿ",
                    "params": {
                        "keyword": "ç¾é£Ÿ",
                        "search_id": get_search_id(),
                        "page": 1,
                        "page_size": 10,
                        "sort": SearchSortType.GENERAL,
                        "note_type": SearchNoteType.ALL
                    }
                },
                {
                    "name": "çƒ­é—¨æ’åº-ç¾é£Ÿ",
                    "params": {
                        "keyword": "ç¾é£Ÿ",
                        "search_id": get_search_id(),
                        "page": 1,
                        "page_size": 10,
                        "sort": SearchSortType.MOST_POPULAR,
                        "note_type": SearchNoteType.ALL
                    }
                },
                {
                    "name": "æœ€æ–°æ’åº-ç¾é£Ÿ",
                    "params": {
                        "keyword": "ç¾é£Ÿ",
                        "search_id": get_search_id(),
                        "page": 1,
                        "page_size": 10,
                        "sort": SearchSortType.LATEST,
                        "note_type": SearchNoteType.ALL
                    }
                },
                {
                    "name": "è§†é¢‘ç±»å‹-ç¾é£Ÿ",
                    "params": {
                        "keyword": "ç¾é£Ÿ",
                        "search_id": get_search_id(),
                        "page": 1,
                        "page_size": 10,
                        "sort": SearchSortType.GENERAL,
                        "note_type": SearchNoteType.VIDEO
                    }
                },
                {
                    "name": "å›¾æ–‡ç±»å‹-ç¾é£Ÿ",
                    "params": {
                        "keyword": "ç¾é£Ÿ",
                        "search_id": get_search_id(),
                        "page": 1,
                        "page_size": 10,
                        "sort": SearchSortType.GENERAL,
                        "note_type": SearchNoteType.IMAGE
                    }
                }
            ]
            
            for test_case in test_cases:
                print(f"\n" + "="*50)
                print(f"ğŸ§ª æµ‹è¯•æ¡ˆä¾‹: {test_case['name']}")
                
                try:
                    # æ‰§è¡Œæœç´¢
                    notes_res = await client.get_note_by_keyword(**test_case['params'])
                    
                    print(f"ğŸ“Š å“åº”åˆ†æ:")
                    print(f"   - å“åº”ç±»å‹: {type(notes_res)}")
                    
                    if isinstance(notes_res, dict):
                        print(f"   - å“åº”é”®: {list(notes_res.keys())}")
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰æƒé™é”™è¯¯
                        if 'code' in notes_res:
                            code = notes_res.get('code')
                            success = notes_res.get('success')
                            msg = notes_res.get('msg', '')
                            print(f"   - é”™è¯¯ä»£ç : {code}")
                            print(f"   - æˆåŠŸçŠ¶æ€: {success}")
                            print(f"   - é”™è¯¯ä¿¡æ¯: {msg}")
                            
                            if code == -104:
                                print(f"   âŒ æƒé™é”™è¯¯ç¡®è®¤")
                            else:
                                print(f"   âœ… éæƒé™é”™è¯¯")
                        
                        # æ£€æŸ¥æ­£å¸¸å“åº”ç»“æ„
                        elif 'has_more' in notes_res:
                            has_more = notes_res.get('has_more')
                            items = notes_res.get('items', [])
                            print(f"   - has_more: {has_more}")
                            print(f"   - itemsæ•°é‡: {len(items) if items else 0}")
                            
                            if len(items) == 0 and not has_more:
                                print(f"   ğŸ¯ ç”¨æˆ·åˆ†ææ­£ç¡®ï¼šå†…å®¹è¢«è¿‡æ»¤ï¼")
                            elif len(items) > 0:
                                print(f"   âœ… æ‰¾åˆ°å†…å®¹ï¼")
                                print(f"   - ç¬¬ä¸€ä¸ªitem: {json.dumps(items[0], indent=2, ensure_ascii=False)[:200]}...")
                        
                        else:
                            print(f"   - æœªçŸ¥å“åº”æ ¼å¼: {json.dumps(notes_res, indent=2, ensure_ascii=False)[:300]}...")
                    
                    else:
                        print(f"   - éå­—å…¸å“åº”: {str(notes_res)[:200]}...")
                        
                except Exception as e:
                    print(f"âŒ æµ‹è¯•å¤±è´¥: {type(e).__name__}: {e}")
                
                # æ·»åŠ å»¶è¿Ÿ
                await asyncio.sleep(3)
            
            # æ¸…ç†èµ„æº
            try:
                await browser_context.close()
                print(f"\nğŸ§¹ æµè§ˆå™¨å·²å…³é—­")
            except:
                pass
                
    except Exception as e:
        print(f"âŒ éªŒè¯å¼‚å¸¸: {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()
    finally:
        os.chdir(original_cwd)

if __name__ == "__main__":
    print("ğŸ”¬ éªŒè¯å†…å®¹è¿‡æ»¤åˆ†æå·¥å…·")
    asyncio.run(verify_content_filtering())
